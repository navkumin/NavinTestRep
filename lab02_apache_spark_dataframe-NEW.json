{
	"jobConfig": {
		"name": "lab02_apache_spark_dataframe-NEW",
		"description": "",
		"role": "arn:aws:iam::100022632938:role/AWSGlueServiceRole-glueworkshop",
		"command": "glueetl",
		"version": "5.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": "5",
		"maxCapacity": 10,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 480,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "lab02_apache_spark_dataframe.py",
		"scriptLocation": "s3://aws-glue-assets-100022632938-us-east-1/scripts/",
		"language": "python-3",
		"spark": false,
		"jobParameters": [],
		"tags": [],
		"jobMode": "NOTEBOOK_MODE",
		"createdOn": "2025-01-28T17:02:40.578Z",
		"developerMode": false,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-100022632938-us-east-1/temporary/",
		"glueHiveMetastore": true,
		"etlAutoTuning": false,
		"pythonShellPrebuiltLibraryOption": "analytics",
		"flexExecution": false,
		"minFlexWorkers": null,
		"sourceControlDetails": {
			"Provider": "GITHUB",
			"Repository": "NavinTestRep",
			"Branch": "main",
			"Folder": ""
		},
		"maintenanceWindow": null,
		"bookmark": "",
		"metrics": "",
		"observabilityMetrics": "",
		"logging": "",
		"sparkPath": "",
		"serverEncryption": false,
		"pythonPath": "",
		"dependentPath": "",
		"referencedPath": "",
		"etlAutoScaling": false,
		"etlAutoTuningJobRules": "",
		"pythonVersion": ""
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n# Retrieve the list of existing buckets\n\nimport boto3\n\ns3 = boto3.client('s3')\nresponse = s3.list_buckets()\n\n# Output the bucket names\nprint('Existing buckets:')\nfor bucket in response['Buckets']:\n    print(f'  {bucket[\"Name\"]}')\n## Read data from Amazon S3 and create DataFrame\n\n## Replace the {S3_PATH} below, with your bucket name.\n\ns3_path = \"glueworkshop-100022632938-us-east-1\" \n\ndf = spark.read.load(\"s3://\" + s3_path + \"/input/lab2/sample.csv\", \n                          format=\"csv\", \n                          sep=\",\", \n                          inferSchema=\"true\",\n                          header=\"true\")\n\n## print schema\ndf.printSchema()\n\n## show 10 records\n\ndf.show(10)\n\ndf.printSchema()\n## Write data as Parquert \n\ndf.write.parquet(\"s3://\" + s3_path + \"/input/lab2/output/parquet/\")\n## reading parquet file\n\ndfpaquet = spark.read.parquet(\"s3://\" + s3_path + \"/input/lab2/output/parquet/\")\n# spark, sparkDFcsv are from the previous example\n# Print the schema in a tree format\n\ndfpaquet.printSchema()\n\n## print 5 records\n\ndfpaquet.show(5)\n## count the total no. of rows in DataFrame\n\ndfpaquet.count()\ndfpaquet.show(5)\n# Select only the \"Country\" column\ndfpaquet.select('Country')\n\n# Select only the \"Country\" column\n# calling action\n\ndfpaquet.select('Country').show()\n\ndfpaquet.select('Country').show(10,truncate=False)\n\n### show multiple columns and create new dataframe\n\ndfselect = dfpaquet.select(dfpaquet['Country'], dfpaquet['ItemType'], dfpaquet['SalesChannel'],dfpaquet['TotalRevenue'])\n\ndfselect.show(10,truncate=False)\n\n### Filter by country\n\ndfselect.filter(dfpaquet['Country'] == 'United Kingdom').show(10,truncate=False)\n\n### Filter by country and Total Revenue and create new dataframe\n\ndfselectfilter = dfselect.filter((dfpaquet['Country'] == 'United Kingdom') & (dfpaquet['TotalRevenue'] <= 200000.00))\n\ndfselectfilter.show(10,truncate=False)\n\n## perform GroupBy operation \n\ndfselectfiltergroupby = dfselectfilter.groupBy(\"ItemType\").sum(\"TotalRevenue\")\n\ndfselectfiltergroupby.show(10,truncate=False)\n\n## perform Order By Operation \n\ndfselectfiltergroupbyorderby = dfselectfiltergroupby.orderBy(\"sum(TotalRevenue)\", ascending=False)\n\ndfselectfiltergroupbyorderby.show(10,truncate=False)\n\n## converting datafrem to createOrReplaceTempView table\n\ndfpaquet.createOrReplaceTempView('dfpaquetsql')\nspark.sql('select * from dfpaquetsql limit 10').show()\nspark.sql('select Country, ItemType , SalesChannel , TotalRevenue from dfpaquetsql limit 10').show()\nspark.sql('select ItemType , sum(TotalRevenue) as SumTotalRevenue from dfpaquetsql group by ItemType order by SumTotalRevenue asc limit 10').show()\ndfcsvsave = spark.sql('select ItemType , sum(TotalRevenue) as SumTotalRevenue from dfpaquetsql group by ItemType order by SumTotalRevenue asc')\n## Save as CSV and creating a single file\n## coalese is very expensive action, it's not recommeneded to use with large dataset\n\nsinglefile = dfcsvsave.coalesce(1) \n\nsinglefile.write.format(\"csv\").mode('overwrite').save(\"s3://\" + s3_path + \"/input/lab2/output/csv/\")\n## stop the current session \n\njob.commit()",
	"notebook": {
		"metadata": {
			"kernelspec": {
				"display_name": "Glue PySpark",
				"language": "python",
				"name": "glue_pyspark"
			},
			"language_info": {
				"codemirror_mode": {
					"name": "python",
					"version": 3
				},
				"file_extension": ".py",
				"mimetype": "text/x-python",
				"name": "Python_Glue_Session",
				"pygments_lexer": "python3"
			}
		},
		"nbformat_minor": 4,
		"nbformat": 4,
		"cells": [
			{
				"cell_type": "markdown",
				"source": "\n# Glue Studio Notebook\nYou are now running a **Glue Studio** notebook; before you can start using your notebook you *must* start an interactive session.\n\n## Available Magics\n|          Magic              |   Type       |                                                                        Description                                                                        |\n|-----------------------------|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n| %%configure                 |  Dictionary  |  A json-formatted dictionary consisting of all configuration parameters for a session. Each parameter can be specified here or through individual magics. |\n| %profile                    |  String      |  Specify a profile in your aws configuration to use as the credentials provider.                                                                          |\n| %iam_role                   |  String      |  Specify an IAM role to execute your session with.                                                                                                        |\n| %region                     |  String      |  Specify the AWS region in which to initialize a session                                                                                                  |\n| %session_id                 |  String      |  Returns the session ID for the running session.                                                                                                          |\n| %connections                |  List        |  Specify a comma separated list of connections to use in the session.                                                                                     |\n| %additional_python_modules  |  List        |  Comma separated list of pip packages, s3 paths or private pip arguments.                                                                                 |\n| %extra_py_files             |  List        |  Comma separated list of additional Python files from S3.                                                                                                 |\n| %extra_jars                 |  List        |  Comma separated list of additional Jars to include in the cluster.                                                                                       |\n| %number_of_workers          |  Integer     |  The number of workers of a defined worker_type that are allocated when a job runs. worker_type must be set too.                                          |\n| %worker_type                |  String      |  Standard, G.1X, *or* G.2X. number_of_workers must be set too. Default is G.1X                                                                            |\n| %glue_version               |  String      |  The version of Glue to be used by this session. Currently, the only valid options are 2.0 and 3.0 (eg: %glue_version 2.0)                                |\n| %security_config            |  String      |  Define a security configuration to be used with this session.                                                                                            |\n| %sql                        |  String      |  Run SQL code. All lines after the initial %%sql magic will be passed as part of the SQL code.                                                            |\n| %streaming                  |  String      |  Changes the session type to Glue Streaming.                                                                                                              |\n| %etl                        |  String      |   Changes the session type to Glue ETL.                                                                                                                   |\n| %status                     |              |  Returns the status of the current Glue session including its duration, configuration and executing user / role.                                          |\n| %stop_session               |              |  Stops the current session.                                                                                                                               |\n| %list_sessions              |              |  Lists all currently running sessions by name and ID.                                                                                                     |\n| %spark_conf                 |  String      |  Specify custom spark configurations for your session. E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer                       |",
				"metadata": {
					"deletable": false,
					"editable": false,
					"trusted": true
				}
			},
			{
				"cell_type": "code",
				"source": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
				"metadata": {
					"trusted": true,
					"editable": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 1,
				"outputs": [
					{
						"name": "stdout",
						"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nSession ID: 9a649ed6-5897-49bc-918e-d02dda538079\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\nWaiting for session 9a649ed6-5897-49bc-918e-d02dda538079 to get into ready status...\nSession 9a649ed6-5897-49bc-918e-d02dda538079 has been created.\n\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "# Retrieve the list of existing buckets\n\nimport boto3\n\ns3 = boto3.client('s3')\nresponse = s3.list_buckets()\n\n# Output the bucket names\nprint('Existing buckets:')\nfor bucket in response['Buckets']:\n    print(f'  {bucket[\"Name\"]}')",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 2,
				"outputs": [
					{
						"name": "stdout",
						"text": "Existing buckets:\n  aws-athena-query-results-us-east-1-100022632938\n  aws-emr-studio-100022632938-us-east-1\n  aws-glue-assets-100022632938-us-east-1\n  cf-templates-1msef5dgfzp1u-us-east-1\n  cf-templates-1msef5dgfzp1u-us-west-2\n  cloudtrail-awslogs-100022632938-hbyrgjlu-isengard-do-not-delete\n  config-bucket-100022632938\n  dmslab-instructor-dmslabcfns3bucket-12yv75td3w25r\n  dmslab-student-dmslabs3bucket-75xjsprwjoab\n  dmslab-student-s3bucketworkgroupa-1bpufnc2m2vdi\n  dmslab-student-s3bucketworkgroupb-1c95pir9dx4b4\n  do-not-delete-gatedgarden-audit-100022632938\n  glue-data-quality-curated-data-bms\n  glue-data-quality-results-etl-bms\n  glue-databrew-immersionday-s3bucket3feedc04-wck36uuq9qab\n  glue-lab-20240430\n  glue-redshift-blog-databucket-q08xx31sufjf\n  glueworkshop-100022632938-us-east-1\n  kinesis-pre-lab-processeds3bucket-oj0w4s6s5g15\n  kinesis-pre-lab-raws3bucket-h0pd24imlm2m\n  mycurdataexport\n  navinp-glue-course\n  stateofutah-bucket1\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## Read data from Amazon S3 and create DataFrame\n\n## Replace the {S3_PATH} below, with your bucket name.\n\ns3_path = \"glueworkshop-100022632938-us-east-1\" \n\ndf = spark.read.load(\"s3://\" + s3_path + \"/input/lab2/sample.csv\", \n                          format=\"csv\", \n                          sep=\",\", \n                          inferSchema=\"true\",\n                          header=\"true\")\n\n## print schema\ndf.printSchema()\n\n## show 10 records\n\ndf.show(10)\n\ndf.printSchema()",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 1,
				"outputs": [
					{
						"name": "stdout",
						"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nSession ID: f70e7f02-a592-4198-a318-159699342fdc\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\nWaiting for session f70e7f02-a592-4198-a318-159699342fdc to get into ready status...\nSession f70e7f02-a592-4198-a318-159699342fdc has been created.\nroot\n |-- uuid: integer (nullable = true)\n |-- country: string (nullable = true)\n |-- itemtype: string (nullable = true)\n |-- saleschannel: string (nullable = true)\n |-- orderpriority: string (nullable = true)\n |-- orderdate: string (nullable = true)\n |-- region: string (nullable = true)\n |-- shipdate: string (nullable = true)\n |-- unitssold: integer (nullable = true)\n |-- unitprice: double (nullable = true)\n |-- unitcost: double (nullable = true)\n |-- totalrevenue: double (nullable = true)\n |-- totalcost: double (nullable = true)\n |-- totalprofit: double (nullable = true)\n\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|     uuid|             country|     itemtype|saleschannel|orderpriority|orderdate|              region|shipdate|unitssold|unitprice|unitcost|totalrevenue| totalcost|totalprofit|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|535113847|          Azerbaijan|       Snacks|      Online|            C|  10/8/14|Middle East and N...|10/23/14|      934|   152.58|   97.44|   142509.72|  91008.96|   51500.76|\n|874708545|              Panama|    Cosmetics|     Offline|            L|  2/22/15|Central America a...| 2/27/15|     4551|    437.2|  263.33|   1989697.2|1198414.83|  791282.37|\n|854349935|Sao Tome and Prin...|       Fruits|     Offline|            M|  12/9/15|  Sub-Saharan Africa| 1/18/16|     9986|     9.33|    6.92|    93169.38|  69103.12|   24066.26|\n|892836844|Sao Tome and Prin...|Personal Care|      Online|            M|  9/17/14|  Sub-Saharan Africa|10/12/14|     9118|    81.73|   56.67|   745214.14| 516717.06|  228497.08|\n|129280602|              Belize|    Household|     Offline|            H|   2/4/10|Central America a...|  3/5/10|     5858|   668.27|  502.54|  3914725.66|2943879.32|  970846.34|\n|473105037|             Denmark|      Clothes|      Online|            C|  2/20/13|              Europe| 2/28/13|     1149|   109.28|   35.84|   125562.72|  41180.16|   84382.56|\n|754046475|             Germany|    Cosmetics|     Offline|            M|  3/31/13|              Europe|  5/3/13|     7964|    437.2|  263.33|   3481860.8|2097160.12| 1384700.68|\n|772153747|              Turkey|       Fruits|      Online|            C|  3/26/12|Middle East and N...|  4/7/12|     6307|     9.33|    6.92|    58844.31|  43644.44|   15199.87|\n|847788178|      United Kingdom|       Snacks|      Online|            H| 12/29/12|              Europe| 1/15/13|     8217|   152.58|   97.44|  1253749.86| 800664.48|  453085.38|\n|471623599|          Kazakhstan|    Cosmetics|      Online|            H|  9/11/15|                Asia| 9/18/15|     2758|    437.2|  263.33|   1205797.6| 726264.14|  479533.46|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\nonly showing top 10 rows\n\nroot\n |-- uuid: integer (nullable = true)\n |-- country: string (nullable = true)\n |-- itemtype: string (nullable = true)\n |-- saleschannel: string (nullable = true)\n |-- orderpriority: string (nullable = true)\n |-- orderdate: string (nullable = true)\n |-- region: string (nullable = true)\n |-- shipdate: string (nullable = true)\n |-- unitssold: integer (nullable = true)\n |-- unitprice: double (nullable = true)\n |-- unitcost: double (nullable = true)\n |-- totalrevenue: double (nullable = true)\n |-- totalcost: double (nullable = true)\n |-- totalprofit: double (nullable = true)\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## Write data as Parquert \n\ndf.write.parquet(\"s3://\" + s3_path + \"/input/lab2/output/parquet/\")",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 4,
				"outputs": [
					{
						"name": "stdout",
						"text": "AnalysisException: path s3://glueworkshop-100022632938-us-east-1/input/lab2/output/parquet already exists.\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## reading parquet file\n\ndfpaquet = spark.read.parquet(\"s3://\" + s3_path + \"/input/lab2/output/parquet/\")",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 6,
				"outputs": [
					{
						"name": "stdout",
						"text": "\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "# spark, sparkDFcsv are from the previous example\n# Print the schema in a tree format\n\ndfpaquet.printSchema()\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 7,
				"outputs": [
					{
						"name": "stdout",
						"text": "root\n |-- uuid: integer (nullable = true)\n |-- country: string (nullable = true)\n |-- itemtype: string (nullable = true)\n |-- saleschannel: string (nullable = true)\n |-- orderpriority: string (nullable = true)\n |-- orderdate: string (nullable = true)\n |-- region: string (nullable = true)\n |-- shipdate: string (nullable = true)\n |-- unitssold: integer (nullable = true)\n |-- unitprice: double (nullable = true)\n |-- unitcost: double (nullable = true)\n |-- totalrevenue: double (nullable = true)\n |-- totalcost: double (nullable = true)\n |-- totalprofit: double (nullable = true)\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## print 5 records\n\ndfpaquet.show(5)",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 8,
				"outputs": [
					{
						"name": "stdout",
						"text": "+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|     uuid|             country|     itemtype|saleschannel|orderpriority|orderdate|              region|shipdate|unitssold|unitprice|unitcost|totalrevenue| totalcost|totalprofit|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|535113847|          Azerbaijan|       Snacks|      Online|            C|  10/8/14|Middle East and N...|10/23/14|      934|   152.58|   97.44|   142509.72|  91008.96|   51500.76|\n|874708545|              Panama|    Cosmetics|     Offline|            L|  2/22/15|Central America a...| 2/27/15|     4551|    437.2|  263.33|   1989697.2|1198414.83|  791282.37|\n|854349935|Sao Tome and Prin...|       Fruits|     Offline|            M|  12/9/15|  Sub-Saharan Africa| 1/18/16|     9986|     9.33|    6.92|    93169.38|  69103.12|   24066.26|\n|892836844|Sao Tome and Prin...|Personal Care|      Online|            M|  9/17/14|  Sub-Saharan Africa|10/12/14|     9118|    81.73|   56.67|   745214.14| 516717.06|  228497.08|\n|129280602|              Belize|    Household|     Offline|            H|   2/4/10|Central America a...|  3/5/10|     5858|   668.27|  502.54|  3914725.66|2943879.32|  970846.34|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\nonly showing top 5 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## count the total no. of rows in DataFrame\n\ndfpaquet.count()\ndfpaquet.show(5)",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					},
					"tags": []
				},
				"execution_count": 9,
				"outputs": [
					{
						"name": "stdout",
						"text": "+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|     uuid|             country|     itemtype|saleschannel|orderpriority|orderdate|              region|shipdate|unitssold|unitprice|unitcost|totalrevenue| totalcost|totalprofit|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|535113847|          Azerbaijan|       Snacks|      Online|            C|  10/8/14|Middle East and N...|10/23/14|      934|   152.58|   97.44|   142509.72|  91008.96|   51500.76|\n|874708545|              Panama|    Cosmetics|     Offline|            L|  2/22/15|Central America a...| 2/27/15|     4551|    437.2|  263.33|   1989697.2|1198414.83|  791282.37|\n|854349935|Sao Tome and Prin...|       Fruits|     Offline|            M|  12/9/15|  Sub-Saharan Africa| 1/18/16|     9986|     9.33|    6.92|    93169.38|  69103.12|   24066.26|\n|892836844|Sao Tome and Prin...|Personal Care|      Online|            M|  9/17/14|  Sub-Saharan Africa|10/12/14|     9118|    81.73|   56.67|   745214.14| 516717.06|  228497.08|\n|129280602|              Belize|    Household|     Offline|            H|   2/4/10|Central America a...|  3/5/10|     5858|   668.27|  502.54|  3914725.66|2943879.32|  970846.34|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\nonly showing top 5 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "# Select only the \"Country\" column\ndfpaquet.select('Country')\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 9,
				"outputs": [
					{
						"name": "stdout",
						"text": "DataFrame[Country: string]\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "# Select only the \"Country\" column\n# calling action\n\ndfpaquet.select('Country').show()\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 10,
				"outputs": [
					{
						"name": "stdout",
						"text": "+--------------------+\n|             Country|\n+--------------------+\n|          Azerbaijan|\n|              Panama|\n|Sao Tome and Prin...|\n|Sao Tome and Prin...|\n|              Belize|\n|             Denmark|\n|             Germany|\n|              Turkey|\n|      United Kingdom|\n|          Kazakhstan|\n|               Haiti|\n|               Italy|\n|               Malta|\n|              Jordan|\n|            Cambodia|\n|Saint Kitts and N...|\n|            Cameroon|\n|             Bahrain|\n|     Solomon Islands|\n|              Monaco|\n+--------------------+\nonly showing top 20 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "dfpaquet.select('Country').show(10,truncate=False)\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 11,
				"outputs": [
					{
						"name": "stdout",
						"text": "+---------------------+\n|Country              |\n+---------------------+\n|Azerbaijan           |\n|Panama               |\n|Sao Tome and Principe|\n|Sao Tome and Principe|\n|Belize               |\n|Denmark              |\n|Germany              |\n|Turkey               |\n|United Kingdom       |\n|Kazakhstan           |\n+---------------------+\nonly showing top 10 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "### show multiple columns and create new dataframe\n\ndfselect = dfpaquet.select(dfpaquet['Country'], dfpaquet['ItemType'], dfpaquet['SalesChannel'],dfpaquet['TotalRevenue'])\n\ndfselect.show(10,truncate=False)\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 12,
				"outputs": [
					{
						"name": "stdout",
						"text": "+---------------------+-------------+------------+------------+\n|Country              |ItemType     |SalesChannel|TotalRevenue|\n+---------------------+-------------+------------+------------+\n|Azerbaijan           |Snacks       |Online      |142509.72   |\n|Panama               |Cosmetics    |Offline     |1989697.2   |\n|Sao Tome and Principe|Fruits       |Offline     |93169.38    |\n|Sao Tome and Principe|Personal Care|Online      |745214.14   |\n|Belize               |Household    |Offline     |3914725.66  |\n|Denmark              |Clothes      |Online      |125562.72   |\n|Germany              |Cosmetics    |Offline     |3481860.8   |\n|Turkey               |Fruits       |Online      |58844.31    |\n|United Kingdom       |Snacks       |Online      |1253749.86  |\n|Kazakhstan           |Cosmetics    |Online      |1205797.6   |\n+---------------------+-------------+------------+------------+\nonly showing top 10 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "### Filter by country\n\ndfselect.filter(dfpaquet['Country'] == 'United Kingdom').show(10,truncate=False)\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 13,
				"outputs": [
					{
						"name": "stdout",
						"text": "+--------------+---------------+------------+------------+\n|Country       |ItemType       |SalesChannel|TotalRevenue|\n+--------------+---------------+------------+------------+\n|United Kingdom|Snacks         |Online      |1253749.86  |\n|United Kingdom|Clothes        |Offline     |961008.32   |\n|United Kingdom|Personal Care  |Offline     |337626.63   |\n|United Kingdom|Office Supplies|Offline     |3431876.7   |\n|United Kingdom|Personal Care  |Offline     |161988.86   |\n|United Kingdom|Personal Care  |Online      |673863.85   |\n|United Kingdom|Personal Care  |Online      |380534.88   |\n|United Kingdom|Baby Food      |Offline     |16593.2     |\n|United Kingdom|Household      |Offline     |5328116.71  |\n|United Kingdom|Cereal         |Offline     |825679.8    |\n+--------------+---------------+------------+------------+\nonly showing top 10 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "### Filter by country and Total Revenue and create new dataframe\n\ndfselectfilter = dfselect.filter((dfpaquet['Country'] == 'United Kingdom') & (dfpaquet['TotalRevenue'] <= 200000.00))\n\ndfselectfilter.show(10,truncate=False)\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 14,
				"outputs": [
					{
						"name": "stdout",
						"text": "+--------------+-------------+------------+------------+\n|Country       |ItemType     |SalesChannel|TotalRevenue|\n+--------------+-------------+------------+------------+\n|United Kingdom|Personal Care|Offline     |161988.86   |\n|United Kingdom|Baby Food    |Offline     |16593.2     |\n|United Kingdom|Personal Care|Offline     |181277.14   |\n|United Kingdom|Vegetables   |Offline     |91665.7     |\n|United Kingdom|Fruits       |Online      |33317.43    |\n|United Kingdom|Fruits       |Online      |35080.8     |\n|United Kingdom|Snacks       |Offline     |24260.22    |\n|United Kingdom|Fruits       |Online      |78810.51    |\n|United Kingdom|Snacks       |Offline     |108789.54   |\n|United Kingdom|Fruits       |Online      |75386.4     |\n+--------------+-------------+------------+------------+\nonly showing top 10 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## perform GroupBy operation \n\ndfselectfiltergroupby = dfselectfilter.groupBy(\"ItemType\").sum(\"TotalRevenue\")\n\ndfselectfiltergroupby.show(10,truncate=False)\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 15,
				"outputs": [
					{
						"name": "stdout",
						"text": "+---------------+------------------+\n|ItemType       |sum(TotalRevenue) |\n+---------------+------------------+\n|Cosmetics      |73886.8           |\n|Beverages      |2300803.05        |\n|Fruits         |1491064.6199999999|\n|Office Supplies|172570.65         |\n|Clothes        |967565.1200000001 |\n|Cereal         |470435.9          |\n|Personal Care  |1086927.27        |\n|Snacks         |414407.28         |\n|Vegetables     |1096136.9         |\n|Household      |177091.55         |\n+---------------+------------------+\nonly showing top 10 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## perform Order By Operation \n\ndfselectfiltergroupbyorderby = dfselectfiltergroupby.orderBy(\"sum(TotalRevenue)\", ascending=False)\n\ndfselectfiltergroupbyorderby.show(10,truncate=False)\n",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 16,
				"outputs": [
					{
						"name": "stdout",
						"text": "+---------------+------------------+\n|ItemType       |sum(TotalRevenue) |\n+---------------+------------------+\n|Beverages      |2300803.05        |\n|Fruits         |1491064.6199999999|\n|Vegetables     |1096136.9         |\n|Personal Care  |1086927.27        |\n|Clothes        |967565.12         |\n|Cereal         |470435.9          |\n|Snacks         |414407.28         |\n|Baby Food      |180482.96         |\n|Household      |177091.55         |\n|Office Supplies|172570.65         |\n+---------------+------------------+\nonly showing top 10 rows\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "markdown",
				"source": "## Spark createOrReplaceTempView()",
				"metadata": {}
			},
			{
				"cell_type": "markdown",
				"source": "How does the createOrReplaceTempView() method work in Spark and what is it used for? One of the main advantages of Apache Spark is working with SQL along with DataFrame/Dataset API. So if you are comfortable with SQL, you can create a temporary view on DataFrame/Dataset by using createOrReplaceTempView() and using SQL to select and manipulate the data.\n\nA Temporary view in Spark is similar to a real SQL table that contains rows and columns but the view is not materialized into files. In this article, we will be discussing what is createOrReplaceTempView() and how to use it to create a temporary view and run Spark SQL queries.",
				"metadata": {}
			},
			{
				"cell_type": "code",
				"source": "## converting datafrem to createOrReplaceTempView table\n\ndfpaquet.createOrReplaceTempView('dfpaquetsql')",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 17,
				"outputs": [
					{
						"name": "stdout",
						"text": "\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "spark.sql('select * from dfpaquetsql limit 10').show()",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 18,
				"outputs": [
					{
						"name": "stdout",
						"text": "+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|     uuid|             country|     itemtype|saleschannel|orderpriority|orderdate|              region|shipdate|unitssold|unitprice|unitcost|totalrevenue| totalcost|totalprofit|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n|965731561|                Togo|         Meat|     Offline|            C| 11/23/15|  Sub-Saharan Africa|11/28/15|      284|   421.89|  364.69|   119816.76| 103571.96|    16244.8|\n|959092128|           Swaziland|       Cereal|     Offline|            M| 12/24/12|  Sub-Saharan Africa|12/29/12|     5529|    205.7|  117.11|   1137315.3| 647501.19|  489814.11|\n|446600949|                Iran|       Cereal|     Offline|            M| 12/10/15|Middle East and N...|  1/4/16|     8000|    205.7|  117.11|   1645600.0|  936880.0|   708720.0|\n|353306853|           Nicaragua|         Meat|     Offline|            C|   5/8/13|Central America a...| 6/13/13|      204|   421.89|  364.69|    86065.56|  74396.76|    11668.8|\n|324571168|               Tonga|       Cereal|     Offline|            M|  7/23/17|Australia and Oce...| 8/12/17|     6676|    205.7|  117.11|   1373253.2| 781826.36|  591426.84|\n|976067721|              Kosovo|    Beverages|      Online|            M|  6/25/15|              Europe| 6/26/15|     8984|    47.45|   31.79|    426290.8| 285601.36|  140689.44|\n|743782842|         South Sudan|   Vegetables|      Online|            C|  3/30/10|  Sub-Saharan Africa| 4/14/10|      726|   154.06|   90.93|   111847.56|  66015.18|   45832.38|\n|834015357|             Senegal|   Vegetables|     Offline|            L|  5/23/17|  Sub-Saharan Africa| 6/27/17|     2533|   154.06|   90.93|   390233.98| 230325.69|  159908.29|\n|273376595|Saint Vincent and...|    Cosmetics|      Online|            M|   9/4/15|Central America a...|10/23/15|     7064|    437.2|  263.33|   3088380.8|1860163.12| 1228217.68|\n|858790385|Federated States ...|Personal Care|      Online|            L|   6/2/11|Australia and Oce...|  7/4/11|     4014|    81.73|   56.67|   328064.22| 227473.38|  100590.84|\n+---------+--------------------+-------------+------------+-------------+---------+--------------------+--------+---------+---------+--------+------------+----------+-----------+\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "spark.sql('select Country, ItemType , SalesChannel , TotalRevenue from dfpaquetsql limit 10').show()",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 19,
				"outputs": [
					{
						"name": "stdout",
						"text": "+--------------------+---------------+------------+------------+\n|             Country|       ItemType|SalesChannel|TotalRevenue|\n+--------------------+---------------+------------+------------+\n|         North Korea|     Vegetables|     Offline|   842554.14|\n|          Mauritania|     Vegetables|     Offline|   960872.22|\n|        Turkmenistan|Office Supplies|      Online|  5593242.69|\n|            Bulgaria|         Cereal|      Online|   1419947.1|\n|      United Kingdom|     Vegetables|      Online|  1169469.46|\n|             Georgia|Office Supplies|     Offline|  2666704.95|\n|United Arab Emirates|         Fruits|      Online|    17615.04|\n|              Taiwan|      Beverages|     Offline|   164983.65|\n|              Angola|         Cereal|     Offline|    698557.2|\n|           Indonesia|        Clothes|     Offline|   351225.92|\n+--------------------+---------------+------------+------------+\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "spark.sql('select ItemType , sum(TotalRevenue) as SumTotalRevenue from dfpaquetsql group by ItemType order by SumTotalRevenue asc limit 10').show()",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 20,
				"outputs": [
					{
						"name": "stdout",
						"text": "+-------------+--------------------+\n|     ItemType|     SumTotalRevenue|\n+-------------+--------------------+\n|       Fruits| 3.806385850799994E8|\n|    Beverages|1.9698494068499994E9|\n|Personal Care|3.3932470151799994E9|\n|      Clothes| 4.565001523200006E9|\n|   Vegetables| 6.355720034159999E9|\n|       Snacks| 6.362447457360001E9|\n|       Cereal|  8.69173378260001E9|\n|    Baby Food|1.069919835359999...|\n|         Meat|1.761195288362998...|\n|    Cosmetics|1.832937566080002...|\n+-------------+--------------------+\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "dfcsvsave = spark.sql('select ItemType , sum(TotalRevenue) as SumTotalRevenue from dfpaquetsql group by ItemType order by SumTotalRevenue asc')",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 21,
				"outputs": [
					{
						"name": "stdout",
						"text": "\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## Save as CSV and creating a single file\n## coalese is very expensive action, it's not recommeneded to use with large dataset\n\nsinglefile = dfcsvsave.coalesce(1) \n\nsinglefile.write.format(\"csv\").mode('overwrite').save(\"s3://\" + s3_path + \"/input/lab2/output/csv/\")",
				"metadata": {
					"trusted": true,
					"vscode": {
						"languageId": "python_glue_session"
					}
				},
				"execution_count": 22,
				"outputs": [
					{
						"name": "stdout",
						"text": "\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "## stop the current session \n\n%stop_session",
				"metadata": {
					"trusted": true,
					"tags": [],
					"vscode": {
						"languageId": "plaintext"
					}
				},
				"execution_count": 2,
				"outputs": [
					{
						"name": "stdout",
						"text": "Stopping session: 9a649ed6-5897-49bc-918e-d02dda538079\nStopped session.\n",
						"output_type": "stream"
					}
				]
			},
			{
				"cell_type": "code",
				"source": "",
				"metadata": {},
				"execution_count": null,
				"outputs": []
			}
		]
	}
}